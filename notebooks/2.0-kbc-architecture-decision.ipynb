{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initial exploration, which mimicked TensorFlow architecture, the difference in the loss obtained from TensorFlow and our implementation was really high. After one epoch, TensorFlow obtained 0.015, while our implementation was 0.08."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this problem, major parts of the network was rewritten in a more \"Chainer\" way. Therefore, Chains and Links were define in the constructor of the model, not in the ```__call__```function, the similar logic was moved in a main \"Model\" to avoid redundancy and facilitate future modification, the training loop use Chaine's iterator to provide the mini-batch data, and finally, instead of reproducing of our function we used Chainer's own functions (e.g: ```F.mean_square_error```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Model super class. It uses the specific models for calculation of the transformation\n",
    "class Model(chainer.Chain):\n",
    "    \"\"\"\n",
    "        This Model wrap other models like CDNA, STP or DNA.\n",
    "        It calls their training and get the generated images and states, \n",
    "        it then compute the losses and other various parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_masks, is_cdna=True, is_dna=False, is_stp=False, prefix=None):\n",
    "        \"\"\"\n",
    "            Initialize a CDNA, STP or DNA through this 'wrapper' Model\n",
    "            Args:\n",
    "                is_cdna: if the model should be an extension of CDNA\n",
    "                is_dna: if the model should be an extension of DNA\n",
    "                is_stp: if the model should be an extension of STP\n",
    "                prefix: appended to the results to differentiate between training and validation\n",
    "                learning_rate: learning rate\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__(\n",
    "        enc0 = L.Convolution2D(in_channels=3, out_channels=32, ksize=(5, 5), stride=2, pad=5/2),\n",
    "            enc1 = L.Convolution2D(in_channels=32, out_channels=32, ksize=(3,3), stride=2, pad=3/2),\n",
    "            enc2 = L.Convolution2D(in_channels=64, out_channels=64, ksize=(3,3), stride=2, pad=3/2),\n",
    "            enc3 = L.Convolution2D(in_channels=74, out_channels=64, ksize=(1,1), stride=1, pad=1/2),\n",
    "            enc4 = L.Deconvolution2D(in_channels=128, out_channels=128, ksize=(3,3), \n",
    "                                     stride=2, outsize=(16,16), pad=3/2),\n",
    "            enc5 = L.Deconvolution2D(in_channels=96, out_channels=96, ksize=(3,3), \n",
    "                                     stride=2, outsize=(32,32), pad=3/2),\n",
    "            enc6 = L.Deconvolution2D(in_channels=64, out_channels=64, ksize=(3,3), \n",
    "                                     stride=2, outsize=(64,64), pad=3/2),\n",
    "\n",
    "            lstm1 = BasicConvLSTMCell(in_size=None, out_size=32),\n",
    "            lstm2 = BasicConvLSTMCell(in_size=None, out_size=32),\n",
    "            lstm3 = BasicConvLSTMCell(in_size=None, out_size=64),\n",
    "            lstm4 = BasicConvLSTMCell(in_size=None, out_size=64),\n",
    "            lstm5 = BasicConvLSTMCell(in_size=None, out_size=128),\n",
    "            lstm6 = BasicConvLSTMCell(in_size=None, out_size=64),\n",
    "            lstm7 = BasicConvLSTMCell(in_size=None, out_size=32),\n",
    "            \n",
    "            norm_enc0 = LayerNormalizationConv2D(),\n",
    "            norm_enc6 = LayerNormalizationConv2D(),\n",
    "            hidden1 = LayerNormalizationConv2D(),\n",
    "            hidden2 = LayerNormalizationConv2D(),\n",
    "            hidden3 = LayerNormalizationConv2D(),\n",
    "            hidden4 = LayerNormalizationConv2D(),\n",
    "            hidden5 = LayerNormalizationConv2D(),\n",
    "            hidden6 = LayerNormalizationConv2D(),\n",
    "            hidden7 = LayerNormalizationConv2D(),\n",
    "\n",
    "            masks = L.Deconvolution2D(in_channels=64, out_channels=num_masks+1, ksize=(1,1), stride=1),\n",
    "\n",
    "            current_state = L.Linear(in_size=None, out_size=5)\n",
    "    )\n",
    "        self.num_masks = num_masks\n",
    "        self.prefix = prefix\n",
    "\n",
    "        model = None\n",
    "        if is_cdna:\n",
    "            model = StatelessCDNA(num_masks)\n",
    "        elif is_stp:\n",
    "            model = StatelessSTP(num_masks)\n",
    "        elif is_dna:\n",
    "            model = StatelessDNA(num_masks)\n",
    "        if model is None:\n",
    "            raise ValueError(\"No network specified\")\n",
    "        else:\n",
    "            self.add_link('model', model)\n",
    "\n",
    "    def __call__(self, images, actions=None, states=None, iter_num=-1.0, \n",
    "                 scheduled_sampling_k=-1, use_state=True, num_masks=10, num_frame_before_prediction=2):\n",
    "         ### ...\n",
    "        # Specific model transformations\n",
    "        transformed = self.model(\n",
    "            [lstm_state1, lstm_state2, lstm_state3, lstm_state4, lstm_state5, lstm_state6, lstm_state7],\n",
    "            [enc0, enc1, enc2, enc3, enc4, enc5, enc6],\n",
    "            [hidden1, hidden2, hidden3, hidden4, hidden5, hidden6, hidden7],\n",
    "            batch_size, prev_image, num_masks, int(color_channels)\n",
    "        )\n",
    "        #...\n",
    "\n",
    "# CDNA, one of the three available model for pixel advection\n",
    "class StatelessCDNA(chainer.Chain):\n",
    "    \"\"\"\n",
    "        Build convolutional lstm video predictor using CDNA\n",
    "        * Because the CDNA does not keep states, it should be passed as a parameter \n",
    "          if one wants to continue learning from previous states\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_masks):\n",
    "        super(StatelessCDNA, self).__init__(\n",
    "            enc7 = L.Deconvolution2D(in_channels=64, out_channels=3, ksize=(1,1), stride=1),\n",
    "            cdna_kerns = L.Linear(in_size=None, out_size=DNA_KERN_SIZE * DNA_KERN_SIZE * num_masks)\n",
    "        )\n",
    "\n",
    "        self.num_masks = num_masks\n",
    "\n",
    "    def __call__(self, lstm_states, encs, hiddens, batch_size, prev_image, num_masks, color_channels):\n",
    "        \"\"\"\n",
    "            Learn through StatelessCDNA.\n",
    "            Args:\n",
    "                lstm_states: An array of computed LSTM transformation\n",
    "                encs: An array of computed transformation\n",
    "                hiddens: An array of hidden layers\n",
    "                batch_size: Size of mini batches\n",
    "                prev_image: The image to transform\n",
    "                num_masks: Number of masks to apply\n",
    "                color_channels: Output color channels\n",
    "            Returns:\n",
    "                transformed: A list of masks to apply on the previous image\n",
    "        \"\"\"\n",
    "        logger = logging.getLogger(__name__)\n",
    "        \n",
    "        lstm_state1, lstm_state2, lstm_state3, lstm_state4, lstm_state5, lstm_state6, lstm_state7 = lstm_states\n",
    "        enc0, enc1, enc2, enc3, enc4, enc5, enc6 = encs\n",
    "        hidden1, hidden2, hidden3, hidden4, hidden5, hidden6, hidden7 = hiddens\n",
    "        \n",
    "        #...\n",
    "        \n",
    "        return transformed\n",
    "    \n",
    "# Training loop\n",
    "# ...\n",
    "while train_iter.epoch < epoch:\n",
    "    itr = train_iter.epoch\n",
    "    batch = train_iter.next()\n",
    "    img_training_set, act_training_set, sta_training_set = concat_examples(batch) # format the batch elements\n",
    "    \n",
    "    # Perform training\n",
    "    logger.info(\"Begining training for mini-batch {0}/{1} of epoch {2}\".format(\n",
    "        str(train_iter.current_position), str(len(images_training)), str(itr+1))\n",
    "    )\n",
    "    optimizer.update(training_model, img_training_set, act_training_set, sta_training_set, \n",
    "                     itr, schedsamp_k, use_state, num_masks, context_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
